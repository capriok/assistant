{
  "name": "assistant",
  "module": "index.ts",
  "type": "module",
  "private": true,
  "scripts": {
    "cli": "bun src/llama-cli.ts",
    "server": "bun src/asststant-server.ts",
    "assist": "bun src/assistant.ts",
    "assist:dev": "bun --watch src/assistant.ts",
    "smoke": "bun scripts/smoke-check.ts",
    "setup:submodules": "git submodule update --init --recursive",
    "build:llama": "cmake -S ./packages/llama.cpp -B ./packages/llama.cpp/build && cmake --build ./packages/llama.cpp/build -j",
    "build:whisper": "cmake -S ./packages/whisper.cpp -B ./packages/whisper.cpp/build && cmake --build ./packages/whisper.cpp/build -j",
    "model:download": "bun run model:download:llama",
    "model:download:llama": "./packages/llama.cpp/build/bin/llama-cli -hf bartowski/Qwen2.5-14B-Instruct-GGUF:Q4_K_M -n 1 -p \"hi\"",
    "model:download:whisper": "./packages/whisper.cpp/models/download-ggml-model.sh base.en",
    "typecheck": "bunx tsc --noEmit",
    "lint": "biome lint .",
    "check": "bun run lint && bun run typecheck && bun run smoke",
    "format": "biome format . --write"
  },
  "devDependencies": {
    "@biomejs/biome": "^2.0.0",
    "@types/bun": "latest",
    "typescript": "^5.9.2"
  },
  "peerDependencies": {}
}
